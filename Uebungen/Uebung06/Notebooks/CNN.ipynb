{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.losses import categorical_crossentropy, sparse_categorical_crossentropy\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple CNN for Edgelovers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a) Generation of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(xlen, ylen, n):\n",
    "    data = np.zeros(shape=(n, xlen, ylen, 1), dtype=np.uint8)\n",
    "    labels = np.zeros(shape=(n), dtype=np.int).squeeze()\n",
    "    \n",
    "    for i in range(n):\n",
    "        img = np.zeros(shape=(xlen, ylen, 1), dtype=np.uint8)\n",
    "        \n",
    "        v_or_h = np.random.randint(0, 2)\n",
    "        lines = 10\n",
    "        \n",
    "        if v_or_h: # horizontal\n",
    "            label = 0\n",
    "            for _ in range(lines):\n",
    "                y = np.random.randint(0, ylen)\n",
    "                x1 = np.random.randint(0, xlen - 10)\n",
    "                x2 = x1 + 10\n",
    "                img[y, x1:x2] = 255\n",
    "        else:  # vertical\n",
    "            label = 1\n",
    "            for _ in range(lines):\n",
    "                x = np.random.randint(0, xlen)\n",
    "                y1 = np.random.randint(0, ylen - 10)\n",
    "                y2 = y1 + 10\n",
    "                img[y1:y2, x] = 255\n",
    "        \n",
    "        data[i] = img.copy()\n",
    "        labels[i] = label\n",
    "    return data, labels.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0, y0 = generate_data(50, 50, 1000)\n",
    "x2, y2 = generate_data(50, 50, 1000);\n",
    "y0 = to_categorical(y0)\n",
    "y2 = to_categorical(y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = x0[0, :, :, 0]\n",
    "plt.imshow(img)\n",
    "print(y0[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b) Build the simplest possible CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 48, 48, 2)         20        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 24, 24, 2)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                11530     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2)                 22        \n",
      "=================================================================\n",
      "Total params: 11,572\n",
      "Trainable params: 11,572\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/100\n",
      "1000/1000 [==============================] - 1s 548us/sample - loss: 4.0276 - accuracy: 0.6660 - val_loss: 0.3637 - val_accuracy: 0.8180\n",
      "Epoch 2/100\n",
      "1000/1000 [==============================] - 0s 63us/sample - loss: 0.3168 - accuracy: 0.8610 - val_loss: 0.2749 - val_accuracy: 0.9040\n",
      "Epoch 3/100\n",
      "1000/1000 [==============================] - 0s 66us/sample - loss: 0.2264 - accuracy: 0.9070 - val_loss: 0.2004 - val_accuracy: 0.9370\n",
      "Epoch 4/100\n",
      "1000/1000 [==============================] - 0s 61us/sample - loss: 0.1542 - accuracy: 0.9470 - val_loss: 0.1552 - val_accuracy: 0.9490\n",
      "Epoch 5/100\n",
      "1000/1000 [==============================] - 0s 62us/sample - loss: 0.1104 - accuracy: 0.9650 - val_loss: 0.1273 - val_accuracy: 0.9590\n",
      "Epoch 6/100\n",
      "1000/1000 [==============================] - 0s 62us/sample - loss: 0.0815 - accuracy: 0.9730 - val_loss: 0.1087 - val_accuracy: 0.9640\n",
      "Epoch 7/100\n",
      "1000/1000 [==============================] - 0s 61us/sample - loss: 0.0635 - accuracy: 0.9780 - val_loss: 0.0958 - val_accuracy: 0.9680\n",
      "Epoch 8/100\n",
      "1000/1000 [==============================] - 0s 67us/sample - loss: 0.0507 - accuracy: 0.9830 - val_loss: 0.0882 - val_accuracy: 0.9690\n",
      "Epoch 9/100\n",
      "1000/1000 [==============================] - 0s 68us/sample - loss: 0.0420 - accuracy: 0.9860 - val_loss: 0.0824 - val_accuracy: 0.9690\n",
      "Epoch 10/100\n",
      "1000/1000 [==============================] - 0s 66us/sample - loss: 0.0347 - accuracy: 0.9890 - val_loss: 0.0783 - val_accuracy: 0.9720\n",
      "Epoch 11/100\n",
      "1000/1000 [==============================] - 0s 63us/sample - loss: 0.0251 - accuracy: 0.9910 - val_loss: 0.0387 - val_accuracy: 0.9840\n",
      "Epoch 12/100\n",
      "1000/1000 [==============================] - 0s 63us/sample - loss: 0.0180 - accuracy: 0.9910 - val_loss: 0.0317 - val_accuracy: 0.9850\n",
      "Epoch 13/100\n",
      "1000/1000 [==============================] - 0s 60us/sample - loss: 0.0152 - accuracy: 0.9920 - val_loss: 0.0282 - val_accuracy: 0.9860\n",
      "Epoch 14/100\n",
      "1000/1000 [==============================] - 0s 69us/sample - loss: 0.0136 - accuracy: 0.9920 - val_loss: 0.0246 - val_accuracy: 0.9900\n",
      "Epoch 15/100\n",
      "1000/1000 [==============================] - 0s 67us/sample - loss: 0.0115 - accuracy: 0.9940 - val_loss: 0.0223 - val_accuracy: 0.9910\n",
      "Epoch 16/100\n",
      "1000/1000 [==============================] - 0s 67us/sample - loss: 0.0102 - accuracy: 0.9950 - val_loss: 0.0206 - val_accuracy: 0.9920\n",
      "Epoch 17/100\n",
      "1000/1000 [==============================] - 0s 67us/sample - loss: 0.0094 - accuracy: 0.9960 - val_loss: 0.0193 - val_accuracy: 0.9930\n",
      "Epoch 18/100\n",
      "1000/1000 [==============================] - 0s 63us/sample - loss: 0.0088 - accuracy: 0.9960 - val_loss: 0.0182 - val_accuracy: 0.9930\n",
      "Epoch 19/100\n",
      "1000/1000 [==============================] - 0s 65us/sample - loss: 0.0083 - accuracy: 0.9960 - val_loss: 0.0173 - val_accuracy: 0.9930\n",
      "Epoch 20/100\n",
      "1000/1000 [==============================] - 0s 60us/sample - loss: 0.0080 - accuracy: 0.9960 - val_loss: 0.0166 - val_accuracy: 0.9940\n",
      "Epoch 21/100\n",
      "1000/1000 [==============================] - 0s 68us/sample - loss: 0.0076 - accuracy: 0.9960 - val_loss: 0.0160 - val_accuracy: 0.9950\n",
      "Epoch 22/100\n",
      "1000/1000 [==============================] - 0s 73us/sample - loss: 0.0074 - accuracy: 0.9960 - val_loss: 0.0155 - val_accuracy: 0.9950\n",
      "Epoch 23/100\n",
      "1000/1000 [==============================] - 0s 61us/sample - loss: 0.0072 - accuracy: 0.9960 - val_loss: 0.0150 - val_accuracy: 0.9950\n",
      "Epoch 24/100\n",
      "1000/1000 [==============================] - 0s 63us/sample - loss: 0.0070 - accuracy: 0.9960 - val_loss: 0.0146 - val_accuracy: 0.9950\n",
      "Epoch 25/100\n",
      "1000/1000 [==============================] - 0s 61us/sample - loss: 0.0068 - accuracy: 0.9960 - val_loss: 0.0141 - val_accuracy: 0.9950\n",
      "Epoch 26/100\n",
      "1000/1000 [==============================] - 0s 65us/sample - loss: 0.0064 - accuracy: 0.9960 - val_loss: 0.0137 - val_accuracy: 0.9950\n",
      "Epoch 27/100\n",
      "1000/1000 [==============================] - 0s 63us/sample - loss: 0.0062 - accuracy: 0.9960 - val_loss: 0.0134 - val_accuracy: 0.9950\n",
      "Epoch 28/100\n",
      "1000/1000 [==============================] - 0s 59us/sample - loss: 0.0060 - accuracy: 0.9970 - val_loss: 0.0131 - val_accuracy: 0.9950\n",
      "Epoch 29/100\n",
      "1000/1000 [==============================] - 0s 61us/sample - loss: 0.0058 - accuracy: 0.9970 - val_loss: 0.0128 - val_accuracy: 0.9950\n",
      "Epoch 30/100\n",
      "1000/1000 [==============================] - 0s 59us/sample - loss: 0.0057 - accuracy: 0.9970 - val_loss: 0.0126 - val_accuracy: 0.9950\n",
      "Epoch 31/100\n",
      "1000/1000 [==============================] - 0s 60us/sample - loss: 0.0056 - accuracy: 0.9970 - val_loss: 0.0124 - val_accuracy: 0.9950\n",
      "Epoch 32/100\n",
      "1000/1000 [==============================] - 0s 63us/sample - loss: 0.0055 - accuracy: 0.9970 - val_loss: 0.0121 - val_accuracy: 0.9950\n",
      "Epoch 33/100\n",
      "1000/1000 [==============================] - 0s 59us/sample - loss: 0.0054 - accuracy: 0.9970 - val_loss: 0.0120 - val_accuracy: 0.9950\n",
      "Epoch 34/100\n",
      "1000/1000 [==============================] - 0s 59us/sample - loss: 0.0052 - accuracy: 0.9970 - val_loss: 0.0117 - val_accuracy: 0.9950\n",
      "Epoch 35/100\n",
      "1000/1000 [==============================] - 0s 60us/sample - loss: 0.0049 - accuracy: 0.9970 - val_loss: 0.0115 - val_accuracy: 0.9950\n",
      "Epoch 36/100\n",
      "1000/1000 [==============================] - 0s 68us/sample - loss: 0.0047 - accuracy: 0.9970 - val_loss: 0.0113 - val_accuracy: 0.9950\n",
      "Epoch 37/100\n",
      "1000/1000 [==============================] - 0s 61us/sample - loss: 0.0046 - accuracy: 0.9970 - val_loss: 0.0111 - val_accuracy: 0.9950\n",
      "Epoch 38/100\n",
      "1000/1000 [==============================] - 0s 65us/sample - loss: 0.0045 - accuracy: 0.9990 - val_loss: 0.0109 - val_accuracy: 0.9970\n",
      "Epoch 39/100\n",
      "1000/1000 [==============================] - 0s 61us/sample - loss: 0.0044 - accuracy: 0.9990 - val_loss: 0.0108 - val_accuracy: 0.9970\n",
      "Epoch 40/100\n",
      "1000/1000 [==============================] - 0s 59us/sample - loss: 0.0043 - accuracy: 0.9980 - val_loss: 0.0106 - val_accuracy: 0.9970\n",
      "Epoch 41/100\n",
      "1000/1000 [==============================] - 0s 64us/sample - loss: 0.0042 - accuracy: 0.9980 - val_loss: 0.0106 - val_accuracy: 0.9970\n",
      "Epoch 42/100\n",
      "1000/1000 [==============================] - 0s 61us/sample - loss: 0.0038 - accuracy: 0.9980 - val_loss: 0.0105 - val_accuracy: 0.9970\n",
      "Epoch 43/100\n",
      "1000/1000 [==============================] - 0s 59us/sample - loss: 0.0037 - accuracy: 0.9980 - val_loss: 0.0105 - val_accuracy: 0.9970\n",
      "Epoch 44/100\n",
      "1000/1000 [==============================] - 0s 65us/sample - loss: 0.0035 - accuracy: 0.9980 - val_loss: 0.0104 - val_accuracy: 0.9970\n",
      "Epoch 45/100\n",
      "1000/1000 [==============================] - 0s 62us/sample - loss: 0.0035 - accuracy: 0.9980 - val_loss: 0.0103 - val_accuracy: 0.9970\n",
      "Epoch 46/100\n",
      "1000/1000 [==============================] - 0s 61us/sample - loss: 0.0034 - accuracy: 0.9980 - val_loss: 0.0103 - val_accuracy: 0.9970\n",
      "Epoch 47/100\n",
      "1000/1000 [==============================] - 0s 59us/sample - loss: 0.0033 - accuracy: 0.9980 - val_loss: 0.0102 - val_accuracy: 0.9970\n",
      "Epoch 48/100\n",
      "1000/1000 [==============================] - 0s 62us/sample - loss: 0.0033 - accuracy: 0.9980 - val_loss: 0.0102 - val_accuracy: 0.9970\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/100\n",
      "1000/1000 [==============================] - 0s 58us/sample - loss: 0.0032 - accuracy: 0.9980 - val_loss: 0.0101 - val_accuracy: 0.9970\n",
      "Epoch 50/100\n",
      "1000/1000 [==============================] - 0s 59us/sample - loss: 0.0032 - accuracy: 0.9980 - val_loss: 0.0101 - val_accuracy: 0.9970\n",
      "Epoch 51/100\n",
      "1000/1000 [==============================] - 0s 62us/sample - loss: 0.0031 - accuracy: 0.9980 - val_loss: 0.0100 - val_accuracy: 0.9970\n",
      "Epoch 52/100\n",
      "1000/1000 [==============================] - 0s 65us/sample - loss: 0.0031 - accuracy: 0.9980 - val_loss: 0.0099 - val_accuracy: 0.9970\n",
      "Epoch 53/100\n",
      "1000/1000 [==============================] - 0s 58us/sample - loss: 0.0030 - accuracy: 0.9980 - val_loss: 0.0099 - val_accuracy: 0.9970\n",
      "Epoch 54/100\n",
      "1000/1000 [==============================] - 0s 66us/sample - loss: 0.0030 - accuracy: 0.9980 - val_loss: 0.0098 - val_accuracy: 0.9970\n",
      "Epoch 55/100\n",
      "1000/1000 [==============================] - 0s 61us/sample - loss: 0.0029 - accuracy: 0.9980 - val_loss: 0.0098 - val_accuracy: 0.9970\n",
      "Epoch 56/100\n",
      "1000/1000 [==============================] - 0s 59us/sample - loss: 0.0029 - accuracy: 0.9980 - val_loss: 0.0097 - val_accuracy: 0.9970\n",
      "Epoch 57/100\n",
      "1000/1000 [==============================] - 0s 60us/sample - loss: 0.0029 - accuracy: 0.9980 - val_loss: 0.0097 - val_accuracy: 0.9970\n",
      "Epoch 58/100\n",
      "1000/1000 [==============================] - 0s 63us/sample - loss: 0.0028 - accuracy: 0.9980 - val_loss: 0.0097 - val_accuracy: 0.9970\n",
      "Epoch 59/100\n",
      "1000/1000 [==============================] - 0s 64us/sample - loss: 0.0027 - accuracy: 0.9980 - val_loss: 0.0096 - val_accuracy: 0.9970\n",
      "Epoch 60/100\n",
      "1000/1000 [==============================] - 0s 63us/sample - loss: 0.0026 - accuracy: 0.9980 - val_loss: 0.0095 - val_accuracy: 0.9970\n",
      "Epoch 61/100\n",
      "1000/1000 [==============================] - 0s 65us/sample - loss: 0.0023 - accuracy: 0.9980 - val_loss: 0.0094 - val_accuracy: 0.9970\n",
      "Epoch 62/100\n",
      "1000/1000 [==============================] - 0s 63us/sample - loss: 0.0022 - accuracy: 0.9980 - val_loss: 0.0093 - val_accuracy: 0.9970\n",
      "Epoch 63/100\n",
      "1000/1000 [==============================] - 0s 65us/sample - loss: 0.0021 - accuracy: 0.9980 - val_loss: 0.0093 - val_accuracy: 0.9970\n",
      "Epoch 64/100\n",
      "1000/1000 [==============================] - 0s 63us/sample - loss: 0.0021 - accuracy: 0.9980 - val_loss: 0.0092 - val_accuracy: 0.9970\n",
      "Epoch 65/100\n",
      "1000/1000 [==============================] - 0s 63us/sample - loss: 0.0020 - accuracy: 0.9980 - val_loss: 0.0092 - val_accuracy: 0.9970\n",
      "Epoch 66/100\n",
      "1000/1000 [==============================] - 0s 70us/sample - loss: 0.0020 - accuracy: 0.9980 - val_loss: 0.0092 - val_accuracy: 0.9970\n",
      "Epoch 67/100\n",
      "1000/1000 [==============================] - 0s 62us/sample - loss: 0.0020 - accuracy: 0.9980 - val_loss: 0.0092 - val_accuracy: 0.9970\n",
      "Epoch 68/100\n",
      "1000/1000 [==============================] - 0s 68us/sample - loss: 0.0020 - accuracy: 0.9980 - val_loss: 0.0092 - val_accuracy: 0.9970\n",
      "Epoch 69/100\n",
      "1000/1000 [==============================] - 0s 58us/sample - loss: 0.0019 - accuracy: 0.9980 - val_loss: 0.0092 - val_accuracy: 0.9970\n",
      "Epoch 70/100\n",
      "1000/1000 [==============================] - 0s 62us/sample - loss: 0.0019 - accuracy: 0.9980 - val_loss: 0.0092 - val_accuracy: 0.9970\n",
      "Epoch 71/100\n",
      "1000/1000 [==============================] - 0s 61us/sample - loss: 0.0019 - accuracy: 0.9980 - val_loss: 0.0092 - val_accuracy: 0.9970\n",
      "Epoch 72/100\n",
      "1000/1000 [==============================] - 0s 59us/sample - loss: 0.0019 - accuracy: 0.9980 - val_loss: 0.0092 - val_accuracy: 0.9970\n",
      "Epoch 73/100\n",
      "1000/1000 [==============================] - 0s 59us/sample - loss: 0.0019 - accuracy: 0.9980 - val_loss: 0.0092 - val_accuracy: 0.9970\n",
      "Epoch 74/100\n",
      "1000/1000 [==============================] - 0s 59us/sample - loss: 0.0019 - accuracy: 0.9980 - val_loss: 0.0092 - val_accuracy: 0.9970\n",
      "Epoch 75/100\n",
      "1000/1000 [==============================] - 0s 59us/sample - loss: 0.0018 - accuracy: 0.9980 - val_loss: 0.0092 - val_accuracy: 0.9970\n",
      "Epoch 76/100\n",
      "1000/1000 [==============================] - 0s 62us/sample - loss: 0.0018 - accuracy: 0.9980 - val_loss: 0.0092 - val_accuracy: 0.9970\n",
      "Epoch 77/100\n",
      "1000/1000 [==============================] - 0s 59us/sample - loss: 0.0018 - accuracy: 0.9980 - val_loss: 0.0091 - val_accuracy: 0.9970\n",
      "Epoch 78/100\n",
      "1000/1000 [==============================] - 0s 60us/sample - loss: 0.0018 - accuracy: 0.9990 - val_loss: 0.0091 - val_accuracy: 0.9970\n",
      "Epoch 79/100\n",
      "1000/1000 [==============================] - 0s 65us/sample - loss: 0.0018 - accuracy: 0.9990 - val_loss: 0.0091 - val_accuracy: 0.9970\n",
      "Epoch 80/100\n",
      "1000/1000 [==============================] - 0s 63us/sample - loss: 0.0018 - accuracy: 0.9990 - val_loss: 0.0091 - val_accuracy: 0.9970\n",
      "Epoch 81/100\n",
      "1000/1000 [==============================] - 0s 61us/sample - loss: 0.0018 - accuracy: 0.9990 - val_loss: 0.0091 - val_accuracy: 0.9970\n",
      "Epoch 82/100\n",
      "1000/1000 [==============================] - 0s 59us/sample - loss: 0.0018 - accuracy: 0.9990 - val_loss: 0.0091 - val_accuracy: 0.9970\n",
      "Epoch 83/100\n",
      "1000/1000 [==============================] - 0s 64us/sample - loss: 0.0018 - accuracy: 0.9990 - val_loss: 0.0092 - val_accuracy: 0.9970\n",
      "Epoch 84/100\n",
      "1000/1000 [==============================] - 0s 60us/sample - loss: 0.0017 - accuracy: 0.9990 - val_loss: 0.0092 - val_accuracy: 0.9970\n",
      "Epoch 85/100\n",
      "1000/1000 [==============================] - 0s 57us/sample - loss: 0.0017 - accuracy: 0.9990 - val_loss: 0.0091 - val_accuracy: 0.9970\n",
      "Epoch 86/100\n",
      "1000/1000 [==============================] - 0s 59us/sample - loss: 0.0017 - accuracy: 0.9990 - val_loss: 0.0092 - val_accuracy: 0.9970\n",
      "Epoch 87/100\n",
      "1000/1000 [==============================] - 0s 65us/sample - loss: 0.0017 - accuracy: 0.9990 - val_loss: 0.0092 - val_accuracy: 0.9970\n",
      "Epoch 88/100\n",
      "1000/1000 [==============================] - 0s 64us/sample - loss: 0.0017 - accuracy: 0.9990 - val_loss: 0.0092 - val_accuracy: 0.9970\n",
      "Epoch 89/100\n",
      "1000/1000 [==============================] - 0s 63us/sample - loss: 0.0017 - accuracy: 0.9990 - val_loss: 0.0092 - val_accuracy: 0.9970\n",
      "Epoch 90/100\n",
      "1000/1000 [==============================] - 0s 59us/sample - loss: 0.0017 - accuracy: 0.9990 - val_loss: 0.0092 - val_accuracy: 0.9970\n",
      "Epoch 91/100\n",
      "1000/1000 [==============================] - 0s 62us/sample - loss: 0.0017 - accuracy: 0.9990 - val_loss: 0.0092 - val_accuracy: 0.9970\n",
      "Epoch 92/100\n",
      "1000/1000 [==============================] - 0s 62us/sample - loss: 0.0017 - accuracy: 0.9990 - val_loss: 0.0092 - val_accuracy: 0.9970\n",
      "Epoch 93/100\n",
      "1000/1000 [==============================] - 0s 63us/sample - loss: 0.0017 - accuracy: 0.9990 - val_loss: 0.0092 - val_accuracy: 0.9970\n",
      "Epoch 94/100\n",
      "1000/1000 [==============================] - 0s 59us/sample - loss: 0.0017 - accuracy: 0.9990 - val_loss: 0.0092 - val_accuracy: 0.9970\n",
      "Epoch 95/100\n",
      "1000/1000 [==============================] - 0s 63us/sample - loss: 0.0017 - accuracy: 0.9990 - val_loss: 0.0092 - val_accuracy: 0.9970\n",
      "Epoch 96/100\n",
      "1000/1000 [==============================] - 0s 58us/sample - loss: 0.0017 - accuracy: 0.9990 - val_loss: 0.0092 - val_accuracy: 0.9970\n",
      "Epoch 97/100\n",
      "1000/1000 [==============================] - 0s 63us/sample - loss: 0.0017 - accuracy: 0.9990 - val_loss: 0.0092 - val_accuracy: 0.9970\n",
      "Epoch 98/100\n",
      "1000/1000 [==============================] - 0s 60us/sample - loss: 0.0017 - accuracy: 0.9990 - val_loss: 0.0092 - val_accuracy: 0.9970\n",
      "Epoch 99/100\n",
      "1000/1000 [==============================] - 0s 65us/sample - loss: 0.0017 - accuracy: 0.9990 - val_loss: 0.0092 - val_accuracy: 0.9970\n",
      "Epoch 100/100\n",
      "1000/1000 [==============================] - 0s 66us/sample - loss: 0.0016 - accuracy: 0.9990 - val_loss: 0.0092 - val_accuracy: 0.9970\n",
      "\n",
      "Test loss: 0.009165057095353405\n",
      "Test accuracy: 0.997\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs = 100\n",
    "n_features = 2\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(n_features, kernel_size=(3, 3), strides=(1, 1), activation='relu', input_shape=(50, 50, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.compile(loss=categorical_crossentropy, optimizer=SGD(lr=0.01), metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "print(\"\\n\")\n",
    "\n",
    "model.fit(x0, y0, batch_size=batch_size, epochs=epochs, validation_data=(x2, y2))\n",
    "\n",
    "score = model.evaluate(x2, y2, verbose=0)\n",
    "print()\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c) Visualize the learned kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "conv_layer = model.layers[0]\n",
    "filters, biases = conv_layer.get_weights()\n",
    "\n",
    "count = 0\n",
    "rows, cols = 1, 2\n",
    "fig, axes = plt.subplots(ncols=cols, nrows=rows, figsize=(15,10))\n",
    "for j in range(cols):\n",
    "    f = filters[:, :, 0, count]\n",
    "    axes[j].imshow(f, cmap='gray')\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
