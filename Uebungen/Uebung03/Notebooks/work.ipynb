{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "Software versions": [
        {
         "module": "Python",
         "version": "3.7.4 64bit [GCC 7.3.0]"
        },
        {
         "module": "IPython",
         "version": "7.8.0"
        },
        {
         "module": "OS",
         "version": "Linux 4.15.0 66 generic x86_64 with debian buster sid"
        },
        {
         "module": "numpy",
         "version": "1.17.2"
        },
        {
         "module": "pandas",
         "version": "0.25.1"
        },
        {
         "module": "seaborn",
         "version": "0.9.0"
        },
        {
         "module": "re",
         "version": "2.2.1"
        },
        {
         "module": "random",
         "version": "The 'random' distribution was not found and is required by the application"
        },
        {
         "module": "wget",
         "version": "3.2"
        }
       ]
      },
      "text/html": [
       "<table><tr><th>Software</th><th>Version</th></tr><tr><td>Python</td><td>3.7.4 64bit [GCC 7.3.0]</td></tr><tr><td>IPython</td><td>7.8.0</td></tr><tr><td>OS</td><td>Linux 4.15.0 66 generic x86_64 with debian buster sid</td></tr><tr><td>numpy</td><td>1.17.2</td></tr><tr><td>pandas</td><td>0.25.1</td></tr><tr><td>seaborn</td><td>0.9.0</td></tr><tr><td>re</td><td>2.2.1</td></tr><tr><td>random</td><td>The 'random' distribution was not found and is required by the application</td></tr><tr><td>wget</td><td>3.2</td></tr><tr><td colspan='2'>Mon Nov 11 12:52:50 2019 CET</td></tr></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{|l|l|}\\hline\n",
       "{\\bf Software} & {\\bf Version} \\\\ \\hline\\hline\n",
       "Python & 3.7.4 64bit [GCC 7.3.0] \\\\ \\hline\n",
       "IPython & 7.8.0 \\\\ \\hline\n",
       "OS & Linux 4.15.0 66 generic x86\\_64 with debian buster sid \\\\ \\hline\n",
       "numpy & 1.17.2 \\\\ \\hline\n",
       "pandas & 0.25.1 \\\\ \\hline\n",
       "seaborn & 0.9.0 \\\\ \\hline\n",
       "re & 2.2.1 \\\\ \\hline\n",
       "random & The 'random' distribution was not found and is required by the application \\\\ \\hline\n",
       "wget & 3.2 \\\\ \\hline\n",
       "\\hline \\multicolumn{2}{|l|}{Mon Nov 11 12:52:50 2019 CET} \\\\ \\hline\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "Software versions\n",
       "Python 3.7.4 64bit [GCC 7.3.0]\n",
       "IPython 7.8.0\n",
       "OS Linux 4.15.0 66 generic x86_64 with debian buster sid\n",
       "numpy 1.17.2\n",
       "pandas 0.25.1\n",
       "seaborn 0.9.0\n",
       "re 2.2.1\n",
       "random The 'random' distribution was not found and is required by the application\n",
       "wget 3.2\n",
       "Mon Nov 11 12:52:50 2019 CET"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tarfile\n",
    "import os\n",
    "import seaborn as sns\n",
    "import re\n",
    "import random\n",
    "import wget\n",
    "\n",
    "#np.set_printoptions(suppress=True, linewidth=np.inf)\n",
    "np.set_printoptions(suppress=True, formatter={'float': '{: 0.6f}'.format})\n",
    "\n",
    "%reload_ext version_information\n",
    "%version_information numpy, pandas, seaborn, re, random, wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already downloaded.\n",
      "File already extracted.\n"
     ]
    }
   ],
   "source": [
    "filename = \"20news-18828\"\n",
    "url = 'http://qwone.com/~jason/20Newsgroups/20news-18828.tar.gz'\n",
    "tar_file_name = \"../data/\" + filename + \".tar.gz\"\n",
    "untar_file_name = \"../data/\"\n",
    "\n",
    "if not os.path.isfile(tar_file_name):\n",
    "    wget.download(url, tar_file_name)\n",
    "else:\n",
    "    print(\"File already downloaded.\")\n",
    "\n",
    "if not os.path.isdir(untar_file_name + filename):\n",
    "    tarfile.open(tar_file_name, \"r:gz\").extractall(untar_file_name)\n",
    "else: \n",
    "    print(\"File already extracted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsgroups = [\"alt.atheism\", \"comp.graphics\", \"sci.space\", \"talk.religion.misc\"]\n",
    "data_raw = []\n",
    "labels = []\n",
    "for path, _, files in os.walk(untar_file_name + filename):\n",
    "    directory = path.split('/')[-1]\n",
    "    if directory not in newsgroups:\n",
    "        continue\n",
    "    for file in files:\n",
    "        with open(os.path.join(path, file), encoding=\"iso-8859-1\") as myfile:\n",
    "            data_raw.append(myfile.read())\n",
    "            labels.append(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "String-Einträge im Array: 3387\n"
     ]
    }
   ],
   "source": [
    "n_entries = len(data_raw)\n",
    "print(\"String-Einträge im Array: {}\".format(n_entries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_partition = [data_raw[i].partition('\\n\\n')[-1] for i in range(len(data_raw))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_regex = [re.compile(r\"(?u)\\b[a-zA-Z]+\\b\").findall(data_partition[i].lower()) for i in range(len(data_partition))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "different_tokens = []\n",
    "for tokens in data_regex:\n",
    "    different_tokens.extend(tokens)\n",
    "different_tokens = list(dict.fromkeys(different_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verschiedene Tokens: 34588\n"
     ]
    }
   ],
   "source": [
    "n_tokens = len(different_tokens)\n",
    "print(\"Verschiedene Tokens: {}\".format(n_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_regex, different_tokens):\n",
    "    data = np.zeros(shape=(n_entries, n_tokens), dtype=np.int)\n",
    "    for j, article in enumerate(data_regex):\n",
    "        if not ((j + 1) % 100):\n",
    "            print(\"Article Nr.: {}\\n...\".format(j + 1))\n",
    "\n",
    "        for i, token in enumerate(different_tokens):\n",
    "            count = article.count(token)\n",
    "\n",
    "            if count > 0:\n",
    "                data[j][i] = count\n",
    "                \n",
    "    data = np.asarray(data)\n",
    "    np.save(\"../data/data.npy\", data)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found saved data.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    data = np.load(\"../data/data.npy\")\n",
    "    print(\"Found saved data.\")\n",
    "except IOError:\n",
    "    print(\"Found no saved data. Process data.\")\n",
    "    data = load_data(data_regex, different_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = int(n_entries * 0.6)\n",
    "c = list(zip(data, labels))\n",
    "random.shuffle(c)\n",
    "data, labels = zip(*c)\n",
    "train = data[:n_train]\n",
    "train_lables = labels[:n_train]\n",
    "test = data[n_train:]\n",
    "test_lables = labels[n_train:]\n",
    "n_test = len(test_lables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group(i): alt.atheism\n",
      "pi(A-priori): 0.23917322834645668\n",
      "Nij: 144743\n",
      "nij: [2498  118  426 ...    0    0    1]\n",
      "pij: [ 0.013935  0.000664  0.002381 ...  0.000006  0.000006  0.000011]\n",
      "\n",
      "Group(i): comp.graphics\n",
      "pi(A-priori): 0.2947834645669291\n",
      "Nij: 145996\n",
      "nij: [2176   63  259 ...    0    0    0]\n",
      "pij: [ 0.012055  0.000354  0.001440 ...  0.000006  0.000006  0.000006]\n",
      "\n",
      "Group(i): sci.space\n",
      "pi(A-priori): 0.28641732283464566\n",
      "Nij: 149868\n",
      "nij: [1661   28  246 ...    0    0    0]\n",
      "pij: [ 0.009010  0.000157  0.001339 ...  0.000005  0.000005  0.000005]\n",
      "\n",
      "Group(i): talk.religion.misc\n",
      "pi(A-priori): 0.1796259842519685\n",
      "Nij: 127183\n",
      "nij: [1952   72  415 ...    0    0    0]\n",
      "pij: [ 0.012073  0.000451  0.002572 ...  0.000006  0.000006  0.000006]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Nij = {newsgroups[0] : 0, \n",
    "       newsgroups[1] : 0, \n",
    "       newsgroups[2] : 0, \n",
    "       newsgroups[3] : 0}\n",
    "\n",
    "nij = {newsgroups[0] : np.zeros(n_tokens, dtype=np.int), \n",
    "       newsgroups[1] : np.zeros(n_tokens, dtype=np.int), \n",
    "       newsgroups[2] : np.zeros(n_tokens, dtype=np.int), \n",
    "       newsgroups[3] : np.zeros(n_tokens, dtype=np.int)}\n",
    "\n",
    "pij = {newsgroups[0] : np.zeros(n_tokens), \n",
    "       newsgroups[1] : np.zeros(n_tokens), \n",
    "       newsgroups[2] :\n",
    "       np.zeros(n_tokens), \n",
    "       newsgroups[3] : np.zeros(n_tokens)}\n",
    "\n",
    "pi = {newsgroups[0] : 0.0, \n",
    "      newsgroups[1] : 0.0, \n",
    "      newsgroups[2] : 0.0, \n",
    "      newsgroups[3] : 0.0}\n",
    "\n",
    "for i in range(n_train):\n",
    "    Nij[labels[i]] += train[i].sum()\n",
    "\n",
    "for i in range(n_train):\n",
    "    nij[labels[i]] += train[i]\n",
    "\n",
    "for group in newsgroups:\n",
    "    pij[group] = (nij[group] + 1) / (Nij[group] + n_tokens)\n",
    "    \n",
    "for i in range(n_train):\n",
    "    pi[labels[i]] += 1\n",
    "    \n",
    "for group in newsgroups:\n",
    "    pi[group] /= n_train \n",
    "    \n",
    "for group in newsgroups:\n",
    "    print(\"Group(i): {}\".format(group))\n",
    "    print(\"pi(A-priori): {}\".format(pi[group]))\n",
    "    print(\"Nij: {}\".format(Nij[group]))\n",
    "    print(\"nij: {}\".format(nij[group]))\n",
    "    print(\"pij: {}\".format(pij[group]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 1232; Total: 1355; Accuracy: 90.92%\n"
     ]
    }
   ],
   "source": [
    "corrects = np.full(shape=(n_test), fill_value=False)\n",
    "for i, lable in enumerate(test_lables):\n",
    "    max_p, max_group = -np.inf, None\n",
    "    for group in newsgroups:\n",
    "        p = np.sum(np.log(pij[group]) * test[i])\n",
    "        \n",
    "        if p > max_p:\n",
    "            max_p = p\n",
    "            max_group = group\n",
    "            \n",
    "    corrects[i] = (lable==max_group)\n",
    "print(\"Correct: {}; Total: {}; Accuracy: {}%\".format(corrects.sum(), n_test, np.round(corrects.sum() / n_test, decimals=4)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
