{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1080x540 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0,'/home/henning/git_repos/ummon3/examples')\n",
    "\n",
    "import load_mnist\n",
    "\n",
    "# Some nice default configuration for plots\n",
    "plt.rcParams['figure.figsize'] = 15, 7.5\n",
    "plt.rcParams['axes.grid'] = True\n",
    "plt.gray();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST, Classes:     10\n",
      "Training Images:    (50000, 784)\n",
      "Validation Images:  (10000, 784)\n",
      "Test Images:        (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "# read MNIST data set and scale it\n",
    "X0,y0,Xv,yv,X1,y1 = load_mnist.read([0,1,2,3,4,5,6,7,8,9], path=\"\")\n",
    "x0 = (1.0/255.0)*X0.astype('float64')\n",
    "x1 = (1.0/255.0)*X1.astype('float64')\n",
    "x2 = (1.0/255.0)*Xv.astype('float64')\n",
    "y0 = y0.astype('float64')\n",
    "y1 = y1.astype('float64')\n",
    "y2 = yv.astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x540 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_gallery(data, labels, shape, interpolation='nearest'):\n",
    "    for i in range(data.shape[0]):\n",
    "        plt.subplot(1, data.shape[0], (i + 1))\n",
    "        plt.imshow(data[i].reshape(shape), interpolation=interpolation)\n",
    "        plt.title(labels[i])\n",
    "        plt.xticks(()), plt.yticks(())\n",
    "\n",
    "subsample = np.random.permutation(x0.shape[0])[:5]\n",
    "images = x0[subsample]\n",
    "labels = ['True class: %d' % np.argmax(l) for l in y0[subsample]]\n",
    "plot_gallery(images, labels, shape=(28, 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Globale Arrays und Variablen des Netzwerkes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2)\n"
     ]
    }
   ],
   "source": [
    "# Netzwerkparameter\n",
    "mbs =  32                    # Größe der Minibatches\n",
    "eta = 0.01                   # Lernrate\n",
    "no_hidden = 256              # Anzahl versteckter Neuronen\n",
    "epochs = 15000               # Anzahl Epochen\n",
    "sizes = [784, no_hidden, 10] # dreischichtiges MPL mit 784 Eingangs-, no_hidden versteckten, 10 Ausgangsneuronen\n",
    "num_layers = len(sizes)      # Anzahl Schichten\n",
    "\n",
    "# Arrays für Gewichte und Schwellwerte (initialisiert mit Gaußschem Rauschen)\n",
    "biases = [np.random.randn(y, 1) for y in sizes[1:]] # Schwellwerte\n",
    "weights = [np.random.randn(y, x) for x, y in zip(sizes[:-1], sizes[1:])] #Gewichte\n",
    "print(weights[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Einige Hilfsfunktionen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sigmoid (vektorisiert)\n",
    "def sigmoid(z):\n",
    "    \"\"\"The sigmoid function.\"\"\"\n",
    "    return 1.0/(1.0+np.exp(-z))\n",
    "\n",
    "# Ableitung des Sigmoids\n",
    "def sigmoid_prime(z):\n",
    "    \"\"\"Derivative of the sigmoid function.\"\"\"\n",
    "    return sigmoid(z)*(1-sigmoid(z))\n",
    "\n",
    "# Ableitung der MSE-Kostenfunktion\n",
    "def cost_derivative(output_activations, y):\n",
    "    \"\"\"Return the vector of partial derivatives \\partial C_x /\n",
    "    \\partial a for the output activations.\"\"\"\n",
    "    return (output_activations-y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vorwärtslauf durch das Netzwerk für Testläufe (Prädiktion):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feedforward(a):\n",
    "    \"\"\"Return the output of the network if ``a`` is input.\"\"\"\n",
    "    for b, w in zip(biases, weights):\n",
    "        a = sigmoid(np.dot(w, a)+b)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Backpropagation-Algorithmus für ein Paar aus Input x und Label y:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backprop(x, y):\n",
    "    \"\"\"Return a tuple ``(nabla_b, nabla_w)`` representing the\n",
    "    gradient for the cost function C_x.  ``nabla_b`` and\n",
    "    ``nabla_w`` are layer-by-layer lists of numpy arrays, similar\n",
    "    to ``self.biases`` and ``self.weights``.\"\"\"\n",
    "    \n",
    "    # Initialisiere Updates für Schwellwerte und Gewichte\n",
    "    nabla_b = [np.zeros(b.shape) for b in biases]\n",
    "    nabla_w = [np.zeros(w.shape) for w in weights]\n",
    "    \n",
    "    # Vorwärtslauf\n",
    "    activation = x # Initialisierung a^1 = x\n",
    "    activations = [x] # list to store all the activations, layer by layer\n",
    "    zs = [] # list to store all the z vectors, layer by layer\n",
    "    for b, w in zip(biases, weights):\n",
    "        z = np.dot(w, activation) + b\n",
    "        zs.append(z)\n",
    "        activation = sigmoid(z)\n",
    "        activations.append(activation)\n",
    "    \n",
    "    # Rückwärtslauf\n",
    "    delta = cost_derivative(activations[-1], y) * sigmoid_prime(zs[-1]) # Fehler am Output\n",
    "    \n",
    "    nabla_b[-1] = delta # Update Schwellwert in der Ausgangsschicht\n",
    "    nabla_w[-1] = np.dot(delta, activations[-2].transpose()) # Update Gewichte in der Ausgangsschicht\n",
    "    \n",
    "    \n",
    "    for l in range(2, num_layers): # Backpropagation\n",
    "        z = zs[-l] # gewichteter Input\n",
    "        sp = sigmoid_prime(z) # Ableitung der Aktivierungsfunktion\n",
    "        t = np.dot(weights[-l+1].transpose(), delta)\n",
    "        delta = t * sp # Fehler in Schicht l\n",
    "        nabla_b[-l] = delta # Update Schwellwert \n",
    "        nabla_w[-l] = np.dot(delta, activations[-l-1].transpose()) # Update Gewichte\n",
    "        \n",
    "    return (nabla_b, nabla_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gemitteltes Update über einen Minibatch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_mini_batch(xmb, ymb, eta):\n",
    "    \"\"\"Update the network's weights and biases by applying\n",
    "    gradient descent using backpropagation to a single mini batch.\n",
    "    The ``mini_batch`` is a list of tuples ``(x, y)``, and ``eta``\n",
    "    is the learning rate.\"\"\"\n",
    "    global weights\n",
    "    global biases\n",
    "\n",
    "    # Initialisiere Updates für Schwellwerte und Gewichte\n",
    "    nabla_b = [np.zeros(b.shape) for b in biases]\n",
    "    nabla_w = [np.zeros(w.shape) for w in weights]\n",
    "    \n",
    "    # Gehe durch alle Beispielpaare im Minibatch\n",
    "    for i in range(xmb.shape[0]):\n",
    "        x = np.reshape(xmb[i,:],(xmb.shape[1],1)).copy()\n",
    "        if len(ymb.shape) == 2:\n",
    "            y = np.reshape(ymb[i,:],(ymb.shape[1],1)).copy()\n",
    "        else:\n",
    "            y = ymb[i].copy()\n",
    "        \n",
    "        # Berechne Updates für alle Schichten über Backprop\n",
    "        delta_nabla_b, delta_nabla_w = backprop(x, y)\n",
    "        \n",
    "        # Addiere einzelne Updates auf\n",
    "        nabla_b = [nb+dnb for nb, dnb in zip(nabla_b, delta_nabla_b)]\n",
    "        nabla_w = [nw+dnw for nw, dnw in zip(nabla_w, delta_nabla_w)]\n",
    "    \n",
    "    # Berechne neue Gewichte\n",
    "    weights = [w-(eta/xmb.shape[0])*nw for w, nw in zip(weights, nabla_w)]\n",
    "    biases = [b-(eta/xmb.shape[0])*nb for b, nb in zip(biases, nabla_b)]\n",
    "    \n",
    "    return (weights, biases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hilfsfunktion zur Evaluation des Netzwerkes auf den Testdaten:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(x2, y2):\n",
    "    \"\"\"Return the number of test inputs for which the neural\n",
    "    network outputs the correct result. Note that the neural\n",
    "    network's output is assumed to be the index of whichever\n",
    "    neuron in the final layer has the highest activation.\"\"\"\n",
    "    \n",
    "    correct = 0 # Anzahl korrekt klassifizierter Testbeispiele\n",
    "    \n",
    "    # Gehe den Testdatensatz durch\n",
    "    for i in range(0, x2.shape[0]):\n",
    "        x = np.reshape(x2[i,:],(x2.shape[1],1)).copy()\n",
    "        if len(y2.shape) == 2:\n",
    "            y = np.reshape(y2[i,:],(y2.shape[1],1)).copy()\n",
    "        else:\n",
    "            y = y2[i].copy()\n",
    "        \n",
    "        # Vorwärtslauf\n",
    "        ypred = feedforward(x)\n",
    "        \n",
    "        # Label ist in one-hot-Codierung: korrekte Klasse ist 1, alle anderen 0\n",
    "        c = np.argmax(y)\n",
    "        \n",
    "        # Index des maximal aktivierten Outputs ist die Entscheidung des Netzwerk\n",
    "        cpred = np.argmax(ypred)\n",
    "        \n",
    "        # Falls beide übereinstimmen, addiere zur Gesamtzahl\n",
    "        if c == cpred:\n",
    "            correct += 1\n",
    "        \n",
    "    return correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stochastischer Gradientenabstieg:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SGD(x0, y0, epochs, mini_batch_size, eta, x2, y2):\n",
    "\n",
    "    n_test = x2.shape[0] # Anzahl Testdaten\n",
    "    n = x0.shape[0]      # Anzahl Trainingsdaten\n",
    "    \n",
    "    # gehe durch alle Epochen\n",
    "    accuracys = np.zeros(epochs)\n",
    "    for j in range(epochs):\n",
    "        \n",
    "        # Bringe die Trainingsdaten in eine zufällige Reihenfolge für jede Epoche\n",
    "        p = np.random.permutation(n) # Zufällige Permutation aller Indizes von 0 .. n-1\n",
    "        x0 = x0[p,:]\n",
    "        y0 = y0[p]\n",
    "        \n",
    "        # Zerlege den permutierten Datensatz in Minibatches \n",
    "        for k in range(0, n, mini_batch_size):\n",
    "            xmb = x0[k:k+mini_batch_size,:]\n",
    "            if len(y0.shape) == 2:\n",
    "                ymb = y0[k:k+mini_batch_size,:]\n",
    "            else:\n",
    "                ymb = y0[k:k+mini_batch_size]\n",
    "            update_mini_batch(xmb, ymb, eta)\n",
    "        \n",
    "        # Gib Performance aus\n",
    "        accuracys[j] = evaluate(x2, y2)\n",
    "        improvement = (accuracys[j] - accuracys[max(j - 1, 0)])\n",
    "        improvement_percent = (improvement / accuracys[max(j - 1, 0)]) * 100\n",
    "        print(\"Epoch {}: {} / {}, improvement: {:.2f}% / {}\".format(j, accuracys[j], len(x2), improvement_percent, improvement))\n",
    "    \n",
    "    return accuracys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (2,1) (10,1) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-4a7190039f7d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0maccuracys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mstop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Elapsed time: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstop\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-45-c0bf527f06e9>\u001b[0m in \u001b[0;36mSGD\u001b[0;34m(x0, y0, epochs, mini_batch_size, eta, x2, y2)\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                 \u001b[0mymb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mmini_batch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mupdate_mini_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxmb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mymb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m# Gib Performance aus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-43-187c81101fc4>\u001b[0m in \u001b[0;36mupdate_mini_batch\u001b[0;34m(xmb, ymb, eta)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m# Berechne Updates für alle Schichten über Backprop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mdelta_nabla_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta_nabla_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackprop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m# Addiere einzelne Updates auf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-42-902d3958c2aa>\u001b[0m in \u001b[0;36mbackprop\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# Rückwärtslauf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mdelta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcost_derivative\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msigmoid_prime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Fehler am Output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mnabla_b\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdelta\u001b[0m \u001b[0;31m# Update Schwellwert in der Ausgangsschicht\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-40-e0ed169b63b8>\u001b[0m in \u001b[0;36mcost_derivative\u001b[0;34m(output_activations, y)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \"\"\"Return the vector of partial derivatives \\partial C_x /\n\u001b[1;32m     14\u001b[0m     \\partial a for the output activations.\"\"\"\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0moutput_activations\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (2,1) (10,1) "
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "accuracys = SGD(x0, y0, epochs, mbs, eta, x2, y2)\n",
    "stop = time.time()\n",
    "print(\"Elapsed time: {}\".format(stop - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Evaluation auf den unabhängigen Testdaten:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test accuracy: {0} / {1}\".format(evaluate(x1, y1), x1.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lernkurve (Genauigkeit auf Validierungsdatensatz):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(accuracys/x2.shape[0]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trainierte rezeptive Felder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = range(no_hidden)\n",
    "plot_gallery(weights[0][:15,:],labels, shape=(28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = range(no_hidden)\n",
    "plot_gallery(weights[1],labels, shape=(no_hidden,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
